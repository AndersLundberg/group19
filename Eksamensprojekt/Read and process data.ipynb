{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests, json\n",
    "import pandas as pd, numpy as np\n",
    "import time, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepros(html) :\n",
    "    d=json.loads(html)\n",
    "    \n",
    "    soup = BeautifulSoup(d['result_list_box_html'],'lxml')\n",
    "    \n",
    "    # this selects the main part of the html\n",
    "    tabel = soup.find('div', attrs={'class':'results component--default'})\n",
    "    \n",
    "    # Jobindex contain both own postings and postings from other\n",
    "    # the two are treated differently in the data\n",
    "    # Jobindex' imported postings\n",
    "    others = re.compile('r[\\d]+')\n",
    "    tabel1 = tabel.findAll('div', attrs={'data-beacon-tid':others})\n",
    "    #print(tabel1)\n",
    "\n",
    "    # Jobindex' own postings\n",
    "    own = re.compile('h[\\d]+')\n",
    "    tabel2 = tabel.findAll('div', attrs={'data-beacon-tid':own})\n",
    "    #print(tabel2)\n",
    "    \n",
    "    return tabel, tabel1, tabel2\n",
    "\n",
    "def job_descr_own(tabel2) : # den er ikke færdig: tag <ul> og saml elementer, der hører sammen\n",
    "    desc_own = []\n",
    "\n",
    "    # tag ul skal med \n",
    "    for l in tabel2 :\n",
    "        g = l.findAll('p')\n",
    "        for m in g :\n",
    "            desc_own.append(m.text)\n",
    "    return desc_own\n",
    "\n",
    "def job_descr_oth(tabel1) : # færdig og virker\n",
    "    desc_oth = []\n",
    "    p=re.compile('\"')\n",
    "    lineshift = re.compile('\\n')\n",
    "    besk = []\n",
    "    for t_ in tabel1 :\n",
    "        besk.append(lineshift.sub(\"\", t_.text))\n",
    "    for t in besk :\n",
    "        desc_oth.append(t.split(sep='    ')[1])\n",
    "    return desc_oth\n",
    "    \n",
    "def job_title_oth (tabel) : # færdig og virker\n",
    "    # udled jobs andre\n",
    "    jobs_oth = []\n",
    "    j = tabel.findAll('strong') \n",
    "    for l in j :\n",
    "        jobs_oth.append(l.text)\n",
    "    return jobs_oth\n",
    "\n",
    "\n",
    "def firm_place(tabel) : # tjek den igen, der kommer lidt for mange elementer ud\n",
    "    firm_city=tabel.find_all('b')\n",
    "    #print(firm_city)\n",
    "    firm=[]\n",
    "    city=[]\n",
    "    cc=0\n",
    "    for i in firm_city:\n",
    "        if cc %2==0:\n",
    "            firm.append(i.text)\n",
    "        else :\n",
    "            city.append(i.text)\n",
    "        cc += 1\n",
    "    return firm, city\n",
    "\n",
    "\n",
    "def dates(tabel) : # finds only dates for others; needs also dates for own\n",
    "    dato_site=tabel.find_all('cite')\n",
    "\n",
    "    website=[]\n",
    "    for i in dato_site:\n",
    "        s_txt=i.text\n",
    "        site=s_txt.split(\",\")[0]\n",
    "        website.append(site)\n",
    "\n",
    "    indented=[]\n",
    "    for i in dato_site:\n",
    "        d_txt=i.text\n",
    "        dates=d_txt.split(\",\")\n",
    "        if dates[0] == \"StepStone\":    # Har behov for at blive fixet\n",
    "            indented.append(indented[-1])\n",
    "        else:\n",
    "            indented.append(dates[1])\n",
    "\n",
    "    monthval={'januar':'01','februar':'02', 'marts':'03', 'april':'04', 'maj':'05', 'juni':'06', 'juli':'07','august':'08','september':'09','oktober':'10','november':'11','december':'12'}\n",
    "    indented_d=[]\n",
    "\n",
    "    for i in indented:\n",
    "        datotal=(int(i.replace(i[3:-4], monthval.get(i[5:-5]))))\n",
    "        indented_d.append(datetime.strptime(str(datotal), '%d%m%Y'))\n",
    "    return indented_d\n",
    "\n",
    "\n",
    "\n",
    "#hyper = []\n",
    "#x1 = tabel.findAll('a', attrs={'href':True}) \n",
    "#for x in x1 :\n",
    "#    hyper.append(x.)\n",
    "#    \n",
    "#print(x1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 1535274470.7094152 . Slut: 1535274484.963382 . Linier hentet: 6\n",
      "Kørseltid: 14.25 sekunder\n"
     ]
    }
   ],
   "source": [
    "# select small subsample\n",
    "import random, time\n",
    "base_path = r\"C:\\Notebooks/jobindex.txt\"\n",
    "sample_path = r\"C:\\Notebooks\\group19\\Eksamensprojekt/jobindex_sample.txt\"\n",
    "f = open(base_path,'r')\n",
    "s = open(sample_path, 'w')\n",
    "linienr = 0\n",
    "t0 = time.time()\n",
    "for line in f :\n",
    "    ran = random.uniform(0, 1) \n",
    "    if ran < .0005 :\n",
    "        linienr += 1\n",
    "        s.write(line)\n",
    "f.close()\n",
    "t1 = time.time()\n",
    "print(\"Start:\", t0, \". Slut:\", t1, \". Linier hentet:\", linienr)\n",
    "print(\"Kørseltid:\", round(t1-t0,2), \"sekunder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "desc_own []\n",
      "desc_oth ['Kunne du tænke dig at gøre julen til en god oplevelse for andre.. (Sct.', 'Vi søger snarest muligt vagter til afløsning i travle perioder.', 'Efter nærmere aftale Silkeborg Rygcenter (Arbejdspladsen ligger i Silkeborg kommune) Vi er et tværfagligt behandlingscenter med...', 'Vi søger en ny kollega 30 timer om ugen pr. 1. januar eller snarest derefter.', 'Statoil A/S er altid på udkig efter servicemindede medarbejdere der har \"et glimt i øjet\".', 'På Indre Nørrebro søger vi 30/35timers uddannet pædagog til fritidshjem.', 'Fra 1. januar og indtil 30.april 2010 søger vi en barselsvikar 37 timer ugentligt.', 'Attraktive løn og personaleforhold: Herunder pension og kantineordning For tiltrædelse snarest søges en dygtig all-round butiksassistent til...', 'SuperBrugsen Lystrup ligger 10 km nord for Århus og har 12.000 indbyggere.', 'Hampen Træforarbejdning A/S ønsker at styrke og videreudvikle sin R&D afdeling.', 'Ved Det Sundhedsvidenskabelige Fakultet Statens Institut for Folkesundhed og Trygfondens Forebyggelsescenter Programmet...', 'På grund af sygdom søger vi en tandklinikassistent hurtigst muligt fra nu af og indtil d. 23 december 2009.', 'Moden og selvstændig rengøringsassistent søges gerne med erfaring men det er ingen betingelse.', 'Moden og selvstændig rengøringsassistent søges gerne med erfaring men det er ingen betingelse på Salling.', 'Sæsonen varer fra 18/11-30/12.', 'Interesseret i et job hos Danmarks førende telemarketingbureau?', 'Morgenfrisk rengøringsassistent til erhvervsrengøring.', 'Rengøringsassistent søges til butiksrengøring i Horsens.', 'Ferieafløser søges til rengøring i Assens fra d. 17.12.2009 - 07.01.2010.', 'Stabil afløser søges til diverse rengøringsopgaver i trekantsområdet.']\n",
      "jobs_oth ['Frivillig til juleaften i sognehuset', 'Vagter til ferieafløsning og i travle perioder', 'Pilates instruktør', 'Pædagog', 'Deltidssælger', 'Pædagog til fritidshjem', 'Omsorgsmedhjælper til Strandvænget, hus 15', 'Butiksassistent med ansvar for ferskvareafdeling', 'Delikatesseassistent', 'Forskningsmedarbejder - BESAT', 'Adjunkt i sundhedsfremme og forebyggelse', 'klinikassistent til sygevikariat, deltid eller fuldtid', 'Rengøringsassistent, Holstebro', 'Rengøringsassistent, Salling', 'Medhjælpere til julemarkedet', 'Marketingkonsulent', 'Rengøringsassistent til Randers', 'Butiksrengøring', 'Rengøring - ferieafløsning', 'Rengøringsassistent til trekantsområdet']\n",
      "firm ['Sct. Pauls Kirke', 'Silkeborg Rygcenter v/Lisbeth Lantto og Ole Hansen', 'Spiloppen', 'Statoil', 'Stjerneskuddet, Københavns Kommunes Integrerede Institution', 'Strandvænget, Nyborg', 'Super Spar Holstebro', 'SuperBrugsen', 'Superwood', 'Syddansk Universitet', 'TANDLÆGERNE JACO-HJØRNET I/S', 'THAGAARD RENGØRING ApS', 'THAGAARD RENGØRING ApS', 'TIVOLI VAFFELBAGERI', 'TMTELEMARKETING ApS', 'TOMS RENGØRING, MIDTJYLLAND ApS', 'TOP RENGØRING, VEJLE - ÅRHUS A/S', 'TOP RENGØRING, VEJLE - ÅRHUS A/S', 'TOP RENGØRING, VEJLE - ÅRHUS A/S']\n",
      "city ['ServiceVagten', 'Silkeborg', 'Rødovre', 'Padborg', 'København N', 'Nyborg', 'Holstebro', 'Region Midtjylland', 'Hampen', 'Odense M', 'Grenaa', 'Holstebro', 'Skive', 'København', 'Herlev', 'Randers C', 'Horsens', 'Assens', 'Vejle Øst']\n",
      "79\n",
      "desc_own []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8b9eac9a17c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m#print(len(desc_own))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#print(len(desc_oth))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-8b9eac9a17c1>\u001b[0m in \u001b[0;36mprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"desc_own\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc_own\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mdesc_oth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_descr_oth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'desc_oth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc_oth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-28ee70a987eb>\u001b[0m in \u001b[0;36mjob_descr_oth\u001b[1;34m(tabel1)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mbesk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlineshift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbesk\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdesc_oth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'    '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdesc_oth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_data() :\n",
    "    base_path = r\"C:\\Notebooks\\group19\\Eksamensprojekt/jobindex_sample.txt\" # file with scraped jobindex data\n",
    "\n",
    "    f = open(base_path, 'r') # open the file for reading\n",
    "    \n",
    "    # loop through the file one line at a time\n",
    "    for html in f :\n",
    "        # here the various processing functions will be called\n",
    "        tabel, tabel1, tabel2= prepros(html)\n",
    "        print(len(tabel))\n",
    "\n",
    "        desc_own = job_descr_own(tabel2)\n",
    "        print(\"desc_own\", desc_own)\n",
    "\n",
    "        desc_oth = job_descr_oth(tabel1)\n",
    "        print('desc_oth', desc_oth)\n",
    "        \n",
    "        jobs_oth = job_title_oth(tabel)\n",
    "        print('jobs_oth', jobs_oth)\n",
    "        firm, city = firm_place(tabel)\n",
    "        print('firm', firm)\n",
    "        print('city', city)\n",
    "        \n",
    "#        post_dates = dates(tabel)\n",
    "#        print(post_dates)\n",
    "        \n",
    "    # der skal laves en zip-funktion, så de kan blive sat rigtig sammen\n",
    "#    return desc_own, desc_oth, jobs_oth, firm, city, post_dates\n",
    "    f.close()\n",
    "\n",
    "process_data()\n",
    "#print(len(desc_own))\n",
    "#print(len(desc_oth))\n",
    "#print(len(jobs_oth))\n",
    "#print(len(firm))\n",
    "#print(len(city))\n",
    "#print(len(post_dates))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
