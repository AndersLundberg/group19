{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests, json\n",
    "import pandas as pd, numpy as np\n",
    "import time, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the data\n",
    "\n",
    "The following steps parse the scraped html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first cell defines our parsing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepros(html) :\n",
    "    d=json.loads(html)\n",
    "    \n",
    "    soup = BeautifulSoup(d['result_list_box_html'],'lxml')\n",
    "    \n",
    "    # this selects the main part of the html\n",
    "    tabel = soup.find('div', attrs={'class':'results component--default'})\n",
    "    \n",
    "    # Jobindex contain both own postings and postings from other\n",
    "    # the two are treated differently in the data\n",
    "    # Jobindex' imported postings\n",
    "    others = re.compile('r[\\d]+')\n",
    "    tabel1 = tabel.findAll('div', attrs={'data-beacon-tid':others})\n",
    "#    print(tabel1)\n",
    "\n",
    "    # Jobindex' own postings\n",
    "    own = re.compile('h[\\d]+')\n",
    "    tabel2 = tabel.findAll('div', attrs={'data-beacon-tid':own})\n",
    "    #print(tabel2)\n",
    "    \n",
    "    return tabel, tabel1, tabel2\n",
    "\n",
    "def job_descr_own(tabel2) : # den er færdig (næsten, der kommer lidt snask med, men det er ok)\n",
    "    desc_own = []\n",
    "    lineshift = re.compile('\\n')\n",
    "    # tag ul skal med \n",
    "    for l in tabel2 :\n",
    "        g1 = l.findAll('p') \n",
    "        g2 = l.findAll('li')\n",
    "        qs = ''\n",
    "#        print(g)\n",
    "        for m in g1 :\n",
    "            qs = qs + m.text + \". \" \n",
    "        for m in g2 :\n",
    "            if 'class=' not in m.text :\n",
    "                qs = qs + m.text + \". \" \n",
    "        desc_own.append(lineshift.sub(\"\", qs))\n",
    "    return desc_own\n",
    "\n",
    "def job_descr_oth(tabel1) : # færdig og virker\n",
    "    desc_oth = []\n",
    "    p=re.compile('\"')\n",
    "    lineshift = re.compile('\\n')\n",
    "    besk = []\n",
    "    for t_ in tabel1 :\n",
    "        besk.append(lineshift.sub(\"\", t_.text))\n",
    "    for t in besk :\n",
    "        s = t.split(sep='    ')\n",
    "        if len(s) == 1 :\n",
    "            desc_oth.append(\"\")\n",
    "        else :\n",
    "            desc_oth.append(t.split(sep='    ')[1])\n",
    "    return desc_oth\n",
    "    \n",
    "def job_title_oth (tabel) : # færdig og virker\n",
    "    # udled jobs andre\n",
    "    jobs_oth = []\n",
    "    j = tabel.findAll('strong') \n",
    "    for l in j :\n",
    "        jobs_oth.append(l.text)\n",
    "    return jobs_oth\n",
    "\n",
    "\n",
    "def firm_place(tabel) : # ok\n",
    "    firm=[]\n",
    "    city=[]\n",
    "    for tag in tabel :\n",
    "        firm_city=tag.findAll('b')\n",
    "        if len(firm_city) == 0 :\n",
    "            firm.append(\"Ukendt\")\n",
    "            city.append(\"Uoplyst\")\n",
    "        elif len(firm_city) == 1 :\n",
    "            firm.append(firm_city[0].text)\n",
    "            city.append(\" \")\n",
    "        else :\n",
    "            firm.append(firm_city[0].text)\n",
    "            city.append(firm_city[1].text)\n",
    "    return firm, city\n",
    "\n",
    "\n",
    "def dates(tabel) : # ok\n",
    "    indented_d=[]\n",
    "    for tag in tabel :\n",
    "        dato_site=tag.findAll('time')\n",
    "\n",
    "        monthval={'januar':'01','februar':'02', 'marts':'03', 'april':'04', 'maj':'05', 'juni':'06', 'juli':'07','august':'08','september':'09','oktober':'10','november':'11','december':'12'}\n",
    "\n",
    "        for i in dato_site:\n",
    "            t = i.text.split()\n",
    "            try :\n",
    "                datotal=(t[0][:-1]+ monthval.get(t[1])+ t[2])\n",
    "                indented_d.append(datetime.datetime(t[2], monthval.get(t[1]), t[0][:-1]))\n",
    "#                indented_d.append(time.mktime(datetime.strptime(str(datotal), '%d%m%Y').timetuple()))\n",
    "            except :\n",
    "                indented_d.append(time.time()) # vi bør videreføre sidst kendte værdi også på tværs af sider\n",
    "    return indented_d\n",
    "\n",
    "def firms_own_fct(tabel2):\n",
    "    firms_own = []\n",
    "    for tag in tabel2 :\n",
    "        firms_egne=tag('img')\n",
    "        regex = re.compile('alt=\"(.*?)\" (?!border: 0px; margin: 0)')\n",
    "        firms_own_=regex.findall(str(firms_egne))\n",
    "        if len(firms_own_) == 0 :\n",
    "            firms_own_ = 'Ukendt'\n",
    "        firms_own.append(firms_own_[0])\n",
    "    return firms_own\n",
    "\n",
    "\n",
    "def cities_own(tabel2) :\n",
    "    city_own = []\n",
    "    for tag in tabel2 :\n",
    "        cit = tag('p')\n",
    "        regex = re.compile('</a>, (.+?)\\s*?</p>')\n",
    "        cities = regex.findall(str(cit))\n",
    "        if len(cities) == 0 :\n",
    "            cities = ['Uoplyst']\n",
    "        city_own.append(cities[0])\n",
    "    return city_own\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test the parsing, we select a subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 1535374183.3649042 . Slut: 1535374194.1478522 . Linier hentet: 15\n",
      "Kørseltid: 10.78 sekunder\n"
     ]
    }
   ],
   "source": [
    "# select small subsample\n",
    "import random, time\n",
    "\n",
    "ca_samplesize = 20\n",
    "base_path = r\"C:/Notebooks/jobindex.txt\"\n",
    "sample_path = r\"C:/Notebooks/jobindex_sample.txt\"\n",
    "f = open(base_path,'r')\n",
    "s = open(sample_path, 'w')\n",
    "linienr = 0\n",
    "t0 = time.time()\n",
    "for line in f :\n",
    "    ran = random.uniform(0, 1) \n",
    "    if ran < ca_samplesize/17000 :\n",
    "        linienr += 1\n",
    "        s.write(line)\n",
    "f.close()\n",
    "t1 = time.time()\n",
    "print(\"Start:\", t0, \". Slut:\", t1, \". Linier hentet:\", linienr)\n",
    "print(\"Kørseltid:\", round(t1-t0,2), \"sekunder\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function that governs the parsing and concatanate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procestid er 6 minutter og 31.98 sekunder\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_data() :\n",
    "    t0 = time.time()\n",
    "#    base_path = r\"C:\\Notebooks\\jobindex_sample.txt\" # file with scraped jobindex data\n",
    "    base_path = r\"C:\\Users\\pot\\Documents\\GitHub\\jobindex2.txt\" # file with scraped jobindex data\n",
    "    \n",
    "\n",
    "    f = open(base_path, mode='r', encoding='utf8') # open the file for reading # jobindex2 skal læses med , encoding='utf8'\n",
    "    count = 0\n",
    "    # loop through the file one line at a time\n",
    "\n",
    "    output_oth = pd.DataFrame(columns=['date', 'job_title', 'job_describ', 'city', 'company'])\n",
    "    output_own = pd.DataFrame(columns=['date', 'job_describ', 'city', 'company'])\n",
    "    \n",
    "   \n",
    "    for html in f :\n",
    "        count += 1\n",
    "#        print(count, len(html))\n",
    "        if len(html) == 1 :\n",
    "            continue\n",
    "        # here the various processing functions will be called\n",
    "        tabel, tabel1, tabel2= prepros(html)\n",
    "#        print(len(tabel))\n",
    "\n",
    "        desc_own = job_descr_own(tabel2)\n",
    "#        print(\"desc_own\", '\\n', len(desc_own), '\\n', desc_own)\n",
    "\n",
    "        desc_oth = job_descr_oth(tabel1)\n",
    "#        print('desc_oth', len(desc_oth), desc_oth)\n",
    "        \n",
    "        jobs_oth = job_title_oth(tabel)\n",
    "#        print('jobs_oth', len(jobs_oth), jobs_oth)\n",
    "        \n",
    "        firm_oth, city_oth = firm_place(tabel1)\n",
    "#        print(\"Andre firms:\", len(firm_oth))\n",
    "        \n",
    "        post_dates_oth = dates(tabel1)\n",
    "#        print(\"dates\", len(post_dates_oth))\n",
    "\n",
    "        post_dates_own = dates(tabel2)\n",
    "#        print(\"dates\", len(post_dates_own), post_dates_own)\n",
    "\n",
    "        firms_own = firms_own_fct(tabel2)\n",
    "#        print(\"Egne firms:\", len(firms_own), '\\n', firms_own)\n",
    "\n",
    "        city_own = cities_own(tabel2)\n",
    "#        print(\"Egne city:\", len(city_own), '\\n', city_own)\n",
    "#        print(\"\\n\")\n",
    "    \n",
    "    # der skal laves en zip-funktion, så de kan blive sat rigtig sammen\n",
    "#    return desc_own, desc_oth, jobs_oth, firm, city, post_dates\n",
    "        tmp = pd.DataFrame(list(zip(post_dates_oth, jobs_oth, desc_oth, city_oth, firm_oth)), \n",
    "                           columns=['date', 'job_title', 'job_describ', 'city', 'company'])\n",
    "        output_oth = pd.concat([output_oth, tmp], axis=0, join='inner', ignore_index=True)\n",
    " \n",
    "#        print(\"Dato:\", '\\n', post_dates_own, '\\n')\n",
    "#        print(\"Beskrivelse:\", '\\n', desc_own, '\\n')\n",
    "#        print(\"Byer:\", '\\n', city_own, '\\n')\n",
    "#        print(\"Firma:\", '\\n', firms_own, '\\n')\n",
    "    \n",
    "\n",
    "        tmp2 = pd.DataFrame(list(zip(post_dates_own, desc_own, city_own, firms_own)),\n",
    "                           columns=['date', 'job_describ', 'city', 'company'])\n",
    "        output_own = pd.concat([output_own, tmp2], axis=0, join='inner', ignore_index=True)\n",
    "    f.close()\n",
    "    t1 = time.time()\n",
    "    print(\"Procestid er\", int((t1-t0)/60), \"minutter og\", round((t1-t0)%60, 2), \"sekunder\")\n",
    "    #print(output_oth)\n",
    "    return output_oth, output_own\n",
    "\n",
    "output_oth, output_own = process_data()\n",
    "\n",
    "#Procestid er 17 minutter og 59.43 sekunder for both1\n",
    "#Procestid er 6 minutter og 31.98 sekunder for both2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the outcome with pandas pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122581, 5)\n",
      "(23699, 4)\n",
      "(146280, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pot\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# gem data\n",
    "\n",
    "print(output_oth.shape)\n",
    "print(output_own.shape)\n",
    "\n",
    "df_both = pd.concat([output_oth, output_own], axis=0, join='outer', ignore_index=True)\n",
    "print(df_both.shape)\n",
    "df_both.to_pickle('both2.pkl')\n",
    "\n",
    "#print(df_both.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure to read the pandas pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (471820, 5)\n",
      "\n",
      "\n",
      "                 city  company          date  \\\n",
      "0  Region Midtjylland  ABB A/S  1.535387e+09   \n",
      "\n",
      "                                         job_describ  \\\n",
      "0  Til vores krævende og kompetente kunder som be...   \n",
      "\n",
      "                                           job_title  \n",
      "0  ABB - Salgsingeniør / Lavspændingskomponenter ...   \n",
      "            city                               company          date  \\\n",
      "471818  Brøndby   Strålfors Information Logistics A/S  1.535388e+09   \n",
      "471819  Uoplyst  Entreprenørfirmaet Per Jørgensen ApS  1.535388e+09   \n",
      "\n",
      "                                              job_describ job_title  \n",
      "471818  Strålfors Information Logistics A/S, Brøndby ....       NaN  \n",
      "471819  Entreprenørfirmaet Per Jørgensen ApS, Årslev ....       NaN  \n"
     ]
    }
   ],
   "source": [
    "# læs data \n",
    "ny1 = pd.read_pickle('both1.pkl')\n",
    "ny2 = pd.read_pickle('both2.pkl')\n",
    "\n",
    "df_both = pd.concat([ny1, ny2], axis=0, join='inner', ignore_index=True)\n",
    "\n",
    "print(\"Shape\", df_both.shape)\n",
    "print(\"\\n\")\n",
    "print(df_both.head(1), \"\\n\", df_both.tail(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
